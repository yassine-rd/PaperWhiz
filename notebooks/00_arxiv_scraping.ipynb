{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes the arXiv website for papers in the category \"cs.CV\" (Computer Vision), \"stat.ML\" / \"cs.LG\" (Machine Learning) and \"cs.AI\" (Artificial Intelligence). The papers are then saved in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA_BASE = Path.cwd().parent / \"data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the arXiv website"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a list of keywords that we will use to query the arXiv API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_keywords = [\n",
    "    \"\\\"image segmentation\\\"\",\n",
    "    \"\\\"self-supervised learning\\\"\",\n",
    "    \"\\\"representation learning\\\"\",\n",
    "    \"\\\"image generation\\\"\",\n",
    "    \"\\\"object detection\\\"\",\n",
    "    \"\\\"transfer learning\\\"\",\n",
    "    \"\\\"transformers\\\"\",\n",
    "    \"\\\"adversarial training\",\n",
    "    \"\\\"generative adversarial networks\\\"\",\n",
    "    \"\\\"model compressions\\\"\",\n",
    "    \"\\\"image segmentation\\\"\",\n",
    "    \"\\\"few-shot learning\\\"\",\n",
    "    \"\\\"natural language\\\"\",\n",
    "    \"\\\"graph\\\"\",\n",
    "    \"\\\"colorization\\\"\",\n",
    "    \"\\\"depth estimation\\\"\",\n",
    "    \"\\\"point cloud\\\"\",\n",
    "    \"\\\"structured data\\\"\",\n",
    "    \"\\\"optical flow\\\"\",\n",
    "    \"\\\"reinforcement learning\\\"\",\n",
    "    \"\\\"super resolution\\\"\",\n",
    "    \"\\\"attention\\\"\",\n",
    "    \"\\\"tabular\\\"\",\n",
    "    \"\\\"unsupervised learning\\\"\",\n",
    "    \"\\\"semi-supervised learning\\\"\",\n",
    "    \"\\\"explainable\\\"\",\n",
    "    \"\\\"radiance field\\\"\",\n",
    "    \"\\\"decision tree\\\"\",\n",
    "    \"\\\"time series\\\"\",\n",
    "    \"\\\"molecule\\\"\",\n",
    "    \"\\\"large language models\\\"\",\n",
    "    \"\\\"llms\\\"\",\n",
    "    \"\\\"language models\\\"\",\n",
    "    \"\\\"image classification\\\"\",\n",
    "    \"\\\"document image classification\\\"\",\n",
    "    \"\\\"encoder\\\"\",\n",
    "    \"\\\"decoder\\\"\",\n",
    "    \"\\\"multimodal\\\"\",\n",
    "    \"\\\"multimodal deep learning\\\"\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we define a function that creates a search object using the given query. It sets the maximum number of results for each category to 6000 and sorts them by the last updated date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = arxiv.Client(num_retries=20, page_size=500)\n",
    "\n",
    "\n",
    "def query_with_keywords(query) -> tuple:\n",
    "    \"\"\"\n",
    "    Query the arXiv API for research papers based on a specific query and filter results by selected categories.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to be used for fetching research papers from arXiv.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing three lists - terms, titles, and abstracts of the filtered research papers.\n",
    "        \n",
    "            terms (list): A list of lists, where each inner list contains the categories associated with a research paper.\n",
    "            titles (list): A list of titles of the research papers.\n",
    "            abstracts (list): A list of abstracts (summaries) of the research papers.\n",
    "            urls (list): A list of URLs for the papers' detail page on the arXiv website.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a search object with the query and sorting parameters.\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=6000,\n",
    "        sort_by=arxiv.SortCriterion.LastUpdatedDate\n",
    "    )\n",
    "    \n",
    "    # Initialize empty lists for terms, titles, abstracts, and urls.\n",
    "    terms = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "    urls = []\n",
    "\n",
    "    # For each result in the search...\n",
    "    for res in tqdm(client.results(search), desc=query):\n",
    "        # Check if the primary category of the result is in the specified list.\n",
    "        if res.primary_category in [\"cs.CV\", \"stat.ML\", \"cs.LG\", \"cs.AI\"]:\n",
    "            # If it is, append the result's categories, title, summary, and url to their respective lists.\n",
    "            terms.append(res.categories)\n",
    "            titles.append(res.title)\n",
    "            abstracts.append(res.summary)\n",
    "            urls.append(res.entry_id)\n",
    "\n",
    "    # Return the four lists.\n",
    "    return terms, titles, abstracts, urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"image segmentation\": 3100it [00:49, 62.37it/s]\n",
      "\"self-supervised learning\": 0it [00:03, ?it/s]\n",
      "\"representation learning\": 6586it [01:48, 60.87it/s]\n",
      "\"image generation\": 2286it [00:38, 59.80it/s]\n",
      "\"object detection\": 7055it [02:06, 55.82it/s]\n",
      "\"transfer learning\": 5346it [01:24, 63.51it/s]\n",
      "\"transformers\": 30000it [09:13, 54.18it/s]\n",
      "\"adversarial training: 0it [00:03, ?it/s]\n",
      "\"generative adversarial networks\": 5800it [01:42, 56.82it/s]\n",
      "\"model compressions\": 761it [00:16, 45.18it/s]\n",
      "\"image segmentation\": 3100it [00:47, 65.53it/s]\n",
      "\"few-shot learning\": 0it [00:03, ?it/s]\n",
      "\"natural language\": 14041it [04:16, 54.81it/s]\n",
      "\"graph\": 30000it [08:41, 57.56it/s]\n",
      "\"colorization\": 30000it [08:26, 59.21it/s]\n",
      "\"depth estimation\": 1318it [00:20, 63.67it/s]\n",
      "\"point cloud\": 4776it [01:11, 66.43it/s]\n",
      "\"structured data\": 2020it [00:34, 59.02it/s]\n",
      "\"optical flow\": 1596it [00:25, 61.72it/s]\n",
      "\"reinforcement learning\": 17300it [04:49, 59.70it/s]\n",
      "\"super resolution\": 3100it [00:48, 64.55it/s]\n",
      "\"attention\": 30000it [08:50, 56.55it/s]\n",
      "\"tabular\": 1521it [00:25, 60.73it/s]\n",
      "\"unsupervised learning\": 2857it [00:42, 67.99it/s]\n",
      "\"semi-supervised learning\": 0it [00:03, ?it/s]\n",
      "\"explainable\": 30000it [08:47, 56.86it/s]\n",
      "\"radiance field\": 649it [00:11, 55.18it/s]\n",
      "\"decision tree\": 2630it [00:45, 58.41it/s]\n",
      "\"time series\": 15858it [04:51, 54.32it/s]\n",
      "\"molecule\": 30000it [08:31, 58.62it/s]\n",
      "\"large language models\": 1564it [00:29, 53.72it/s]\n",
      "\"llms\": 886it [00:12, 71.77it/s]\n",
      "\"language models\": 10554it [03:08, 55.92it/s]\n",
      "\"image classification\": 6134it [01:43, 59.27it/s]\n",
      "\"document image classification\": 19it [00:03,  5.46it/s]\n",
      "\"encoder\": 30000it [08:29, 58.85it/s]\n",
      "\"decoder\": 18507it [04:40, 66.00it/s]\n",
      "\"multimodal\": 7402it [01:54, 64.65it/s]\n",
      "\"multimodal deep learning\": 79it [00:03, 20.25it/s]\n"
     ]
    }
   ],
   "source": [
    "all_titles = []\n",
    "all_abstracts = []\n",
    "all_terms = []\n",
    "all_urls = []\n",
    "\n",
    "for query in query_keywords:\n",
    "    terms, titles, abstracts, urls = query_with_keywords(query)\n",
    "    all_titles.extend(titles)\n",
    "    all_abstracts.extend(abstracts)\n",
    "    all_terms.extend(terms)\n",
    "    all_urls.extend(urls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a pandas.DataFrame object to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data = pd.DataFrame({\n",
    "    'titles': all_titles,\n",
    "    'abstracts': all_abstracts,\n",
    "    'terms': all_terms,\n",
    "    'urls': all_urls\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we export the DataFrame to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data.to_csv(PATH_DATA_BASE / 'data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperwhiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
